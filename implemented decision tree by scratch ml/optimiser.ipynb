{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2617ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f7a857b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='latin')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91ce1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "df = df.rename(columns={\"v2\" : \"text\", \"v1\":\"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22aa6781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b287945b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import nltk packages and Punkt Tokenizer Models\n",
    "# import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27c4d0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(['ham','spam'],[0, 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7968bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0f78a7",
   "metadata": {},
   "source": [
    "## Removing all stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7be94db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\divya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fae4f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the punctuations and stopwords\n",
    "import string\n",
    "def text_process(text):\n",
    "    \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c8e38b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5920f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['text']\n",
    "label = df['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaaef83",
   "metadata": {},
   "source": [
    "## Converting words to vectors using TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53415282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 9376)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the text data into vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "# vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(df['text'])\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bd14004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 9376)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features = word_vectors\n",
    "features = vectors\n",
    "# fetures = features.toarray()\n",
    "features = features.toarray().astype(float)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0b06b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #decision tree\n",
    "\n",
    "# import numpy as np\n",
    "# # from Node import Node\n",
    "\n",
    "# class Node:\n",
    "#     def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "#         self.feature = feature\n",
    "#         self.threshold = threshold\n",
    "#         self.left = left\n",
    "#         self.right = right\n",
    "#         self.value = value\n",
    "        \n",
    "#     def is_leaf(self):\n",
    "#         return self.value is not None\n",
    "  \n",
    "  \n",
    "# class DecisionTree:\n",
    "#     #by default it will make root = NUll and assign max_depth and min_samples_split\n",
    "#     def __init__(self, max_depth=10, min_samples_split=2):\n",
    "#         self.max_depth = max_depth\n",
    "#         self.min_samples_split = min_samples_split\n",
    "#         self.root = None\n",
    "        \n",
    "#     # it will check whethr we should stop now or not \n",
    "#     # here if depth is reach our max or class split is divided into 1 or split samples are less min split\n",
    "#     def searchComplete(self, depth):\n",
    "#         if (depth >= self.max_depth or self.class_labels == 1 or self.n_samples < self.min_samples_split):\n",
    "#             return True\n",
    "#         return False\n",
    "    \n",
    "#     def entropy(self,y):\n",
    "#         proportions = np.bincount(y) / len(y)\n",
    "#         entropy = -np.sum([p * np.log2(p) for p in proportions if p > 0])\n",
    "#         return entropy\n",
    "        \n",
    "# \t# make the tree split using threshold value\n",
    "#     def createSplit(self, X , thresh):\n",
    "#         print(X)\n",
    "#         left_idx = np.argwhere(X <= thresh)\n",
    "#         right_idx = np.argwhere(X > thresh)\n",
    "        \n",
    "#         # print(left_idx,right_idx)\n",
    "#         return left_idx, right_idx\n",
    "        \n",
    "# \t# implementing the basic information gain formula finding the left subtree and right subtree and subtracting the child loss from its parent loss\n",
    "#     def informationGain(self, X, y, thresh):\n",
    "#         parentLoss = self.entropy(y)\n",
    "#         left_idx, right_idx = self.createSplit(X, thresh)\n",
    "#         n, n_left , n_right = len(y), len(left_idx), len(right_idx)\n",
    "\n",
    "#         if n_left == 0 or n_right == 0:\n",
    "#             return 0\n",
    "#         childLoss = (n_left / n) * self.entropy(y[left_idx]) + (n_right/ n) * self.entropy(y[right_idx])\n",
    "#         return parentLoss - childLoss\n",
    "\n",
    "# \t# best function to make the split \n",
    "#     def bestSplit(self, X, y , features):\n",
    "#         split = {'score' : -1 , 'feat': None, 'thresh': None}\n",
    "       \n",
    "#         for feat in features:\n",
    "#             X_feat = X[feat]\n",
    "#             thresholds = np.unique(X_feat)\n",
    "#             for thresh in thresholds:\n",
    "#                 score = self.informationGain(X_feat, y, thresh)\n",
    "                \n",
    "#                 if score > split['score']:\n",
    "#                     split['score'] = score\n",
    "#                     split['feat'] = feat\n",
    "#                     split['thresh'] = thresh\n",
    "#         return split['feat'], split['thresh']\n",
    "\n",
    "        \n",
    "#     # will have to build tree with given information of depth and training dataset\n",
    "#     def buildTree(self, X, y, depth = 0):\n",
    "\n",
    "#         self.n_samples, self.n_features = X.shape \n",
    "#         self.class_labels = len(np.unique(y)) \n",
    "            \n",
    "#         # check whether we should stop or not\n",
    "#         if self.searchComplete(depth):\n",
    "#             most_common_Label = np.argmax(np.bincount(y))\n",
    "#             return Node(value = most_common_Label)\n",
    "\n",
    "#         # get best split\n",
    "#         rnd_feats = np.random.choice(self.n_features, self.n_features, replace=False) # generates a new random sample from 1D array\n",
    "#         best_feat, best_thresh = self.bestSplit(X, y, rnd_feats) # this function will return best feature and best threshold \n",
    "         \n",
    "#         # grow child recursively\n",
    "#         left_idx, right_idx = self.createSplit(X[best_feat], best_thresh)\n",
    "#         left_child = self.buildTree(X[left_idx], y[left_idx], depth + 1)\n",
    "#         right_child = self.buildTree(X[right_idx], y[right_idx], depth + 1)\n",
    "#         return Node(best_feat, best_thresh, left_child, right_child)\n",
    "        \n",
    "#     def _traverse_tree(self, x, node):\n",
    "#         if node.is_leaf():\n",
    "#             return node.value\n",
    "        \n",
    "#         if x[node.feature] <= node.threshold:\n",
    "#             return self._traverse_tree(x, node.left)\n",
    "#         return self._traverse_tree(x, node.right)\n",
    "    \n",
    "#     # will call this function in our jupyter notebook during \n",
    "#     # building model instead of calling the prebuilt decision tree using sckit learn \n",
    "#     def fit(self, X, y):\n",
    "#         self.root = self.buildTree(X,y)\n",
    "#         return 0\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         predictions = [self._traverse_tree(x, self.root) for x in X ]\n",
    "#         return np.array(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1646256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "350d4488",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSO:\n",
    "    def __init__(self, particles, dimensions, lb, ub, itrations, c1, c2, w, xr, yr):\n",
    "        self.xr = xr\n",
    "        self.yr = yr\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.p = particles\n",
    "        self.d = dimensions\n",
    "        self.n = itrations\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.w = w\n",
    "        self.fitness_value = np.zeros(particles) + np.inf  # p\n",
    "        self.X = np.random.randint(0, 2, (particles, dimensions))  # pxd\n",
    "        self.V = np.random.randint(0, 2, (particles, dimensions))  # pxd\n",
    "        self.pbest = self.X  # pxd\n",
    "        self.gbest = np.zeros(dimensions)  # d\n",
    "        # ---initialiastion-------------------------\n",
    "        min = np.inf\n",
    "        for i in range(self.p):\n",
    "            fit = self.fitness(self.X[i])\n",
    "            if min > fit:\n",
    "                min = fit\n",
    "                self.gbest = self.X[i]\n",
    "        # -------------------------------------------\n",
    "        self.run()\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def count(self, x):\n",
    "        c = np.sum(x)\n",
    "        return c\n",
    "\n",
    "    def fitness(self, x):\n",
    "        x_train = []\n",
    "        y_train = self.yr\n",
    "\n",
    "        for i in range(self.d):\n",
    "            if x[i] == 1:\n",
    "                x_train.append(self.xr[:, i])\n",
    "\n",
    "        x_train = np.array(x_train).reshape((self.xr.shape[0], -1))\n",
    "\n",
    "        if x_train.shape[1] == 0:\n",
    "            return 0\n",
    "\n",
    "        classifier = DecisionTreeClassifier(max_depth = 3)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        chk = classifier.predict(x_train)\n",
    "        \n",
    "        acc = ((chk == y_train).sum() * 1.0) / len(chk)\n",
    "        return acc\n",
    "\n",
    "    def run(self):\n",
    "        for itr in tqdm(range(int(self.n))):\n",
    "            for i in range(self.p):\n",
    "                if self.fitness(self.X[i]) > self.fitness(self.pbest[i]):\n",
    "                    self.pbest[i] = self.X[i]\n",
    "\n",
    "                if self.fitness(self.X[i] > self.fitness(self.gbest)):\n",
    "                    self.gbest = self.X[i]\n",
    "\n",
    "                if (self.fitness(self.X[i]) == self.fitness(self.gbest)) and (self.count(self.X[i]) < self.count(self.gbest)):\n",
    "                    self.gbest = self.X[i]\n",
    "\n",
    "            r1 = random.uniform(0, 1)\n",
    "            r2 = random.uniform(0, 1)\n",
    "            for p in range(self.p):\n",
    "                for q in range(self.d):\n",
    "                    self.V[p][q] = (self.w * self.V[p][q] + self.c1 * r1 * (self.pbest[p][q] - self.X[p][q]) + self.c2 * r2 * (self.gbest[q] - self.X[p][q]))\n",
    "\n",
    "                    if self.V[p][q] > self.ub:\n",
    "                        self.V[p][q] = self.ub\n",
    "                    if self.V[p][q] < self.lb:\n",
    "                        self.V[p][q] = self.ub\n",
    "\n",
    "                    if self.sigmoid(self.V[p][q]) > random.uniform(0, 1):\n",
    "                        self.X[p][q] = 1\n",
    "                    else:\n",
    "                        self.X[p][q] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f61a464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 30/30 [51:19<00:00, 102.66s/it]\n"
     ]
    }
   ],
   "source": [
    "p = 100 #number of particles\n",
    "d = 1300 #total number of features\n",
    "lb = 0 #min value after normalization\n",
    "ub = 1 #max value after normalization\n",
    "it = 30 #number of itrations\n",
    "c1 = 1.5 # coefficient 1\n",
    "c2 = 1.7 # coefficient 3\n",
    "w = 0.7 #intertia\n",
    "xr = features #dataset under which PSO needs to be performed\n",
    "yr = label #dataset under which PSO needs to be performed\n",
    "pp = PSO(p,d,lb,ub,it,c1,c2,w, xr, yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b87b6363",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "# classifier2 = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ee87198",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = []\n",
    "y_test = label\n",
    "\n",
    "for i in range(d):\n",
    "  if pp.gbest[i] == 1:\n",
    "    input1.append(features[:,i])\n",
    "\n",
    "input1 = np.array(input1).reshape((features.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a900773c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(input1, y_test)\n",
    "print(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdab7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier.predict(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6cb1e658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.8950107681263461\n",
      "Precision score =  1.0\n",
      "Recall score =  0.21686746987951808\n"
     ]
    }
   ],
   "source": [
    "    print('Accuracy score is : ' , format(accuracy_score(y_test, preds)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d1c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, preds):\n",
    "    print(\"Accuracy Score is : \",format(accuracy_score(y_test, dt_pred)))\n",
    "    print('Precision score is : ' , format(precision_score(y_test, dt_pred)))\n",
    "    print('Recall score is : ' , format(recall_score(y_test, dt_pred)))\n",
    "    print('F1 score is : ', format(f1_score(y_test, dt_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f0c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60840cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Predict(message):\n",
    "#     message = [message]\n",
    "#     message = vectorizer.transform(message).toarray()\n",
    "#     print(message.shape)\n",
    "#     predictedValue = classifier1.predict(message)\n",
    "#     if(predictedValue == 0):\n",
    "#         print(\"Ham\")\n",
    "#     else:\n",
    "#         print(\"Spam\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28dcc9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict(df[\"text\"][1])\n",
    "# # for i in range(1,1000):\n",
    "# #     Predict(df[\"text\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac56c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
